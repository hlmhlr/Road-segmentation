# SegRExtNet: A Deep Learning-based road segmentation

This project implements a deep learning model for aerial image segmentation, particularly focusing on roads detection using CNN-based architectures.

---

## ğŸ“ Project Structure

â”œâ”€â”€ checkpoints/ # Saved model weights
â”œâ”€â”€ dataset/ # Your dataset (train, val, test)
â”‚ â”œâ”€â”€ train/image/
â”‚ â”œâ”€â”€ train/mask/
â”‚ â”œâ”€â”€ val/image/
â”‚ â”œâ”€â”€ val/mask/
â”‚ â”œâ”€â”€ test/image/
â”‚ â””â”€â”€ test/mask/
â”œâ”€â”€ outputs/ # Predicted masks from test.py
â”œâ”€â”€ logs/ # Training logs
â”œâ”€â”€ train.py # Training script
â”œâ”€â”€ test.py # Testing/evaluation script
â”œâ”€â”€ model.py # Model architecture (UNet/CompNet)
â”œâ”€â”€ model_mnetv3_2_ca_sa.py # MobileNetV3 + CA + SA model
â”œâ”€â”€ loss.py # Standard and custom loss functions
â”œâ”€â”€ Hybrid_Eloss.py # Custom loss function
â”œâ”€â”€ utils.py # Helper functions
â”œâ”€â”€ data.py # Dataset loading
â”œâ”€â”€ requirements.txt # Required Python packages
â””â”€â”€ README.md # This file

## âš™ï¸ Installation

1. **Clone the repository**

```bash
git clone https://github.com/hlmhlr/Road-segmentation.git
cd road_segmentation
pip install -r requirements.txt

2. **Install dependencies**

```bash
pip install -r requirements.txt

âœ… Tip: Use a virtual environment:

```bash
conda create -n segrext python=3.8
conda activate segrext


## ğŸš€ Usage

â–¶ï¸ Training the Model

python train.py \
    --path ./dataset \
    --checkpoint_path ./checkpoints/best_model.pth \
    --train_log_path ./logs/train_log.txt \
    --batch_size 4 \
    --num_epochs 40



Arguments:

--path: Root path to the dataset.

--checkpoint_path: Where to save the trained .pth model.

--train_log_path: File to log loss and metrics.

--batch_size: Batch size for training.

--num_epochs: Number of training epochs.



## ğŸ§ª Testing / Inference

python test.py \
    --path ./dataset \
    --checkpoint_path ./checkpoints/best_model.pth \
    --results_path ./outputs

Arguments:

--path: Dataset path (should include test/image and test/mask).

--checkpoint_path: Path to the trained model file.

--results_path: Folder to save the predicted masks.


## ğŸ§¾ Dataset Format
The dataset must follow this structure:

dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ image/
â”‚   â””â”€â”€ mask/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ image/
â”‚   â””â”€â”€ mask/
â””â”€â”€ test/
    â”œâ”€â”€ image/
    â””â”€â”€ mask/

All images are kept as .png files.

## ğŸ“ˆ Output & Metrics
At the end of testing, the following segmentation metrics are printed and saved:

Jaccard Index (IoU)

F1 Score

Recall

Precision

Accuracy

F2 Score

Inference FPS (Frames per Second)

Outputs:
Predicted masks are saved to the outputs/ folder.

Evaluation results are stored in a .csv file inside the results directory.

## ğŸ“Œ Notes
Images are resized to 256Ã—256 before inference.

Predicted masks are binarized with a threshold of 0.5.

The model is evaluated on test.py using ground-truth masks.

The entire code supports CUDA if a GPU is available.


---