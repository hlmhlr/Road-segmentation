# SegRExtNet: A Deep Learning-based road segmentation

This project implements a deep learning model for aerial image segmentation, particularly focusing on roads detection using CNN-based architectures.


---
## ğŸ“ Project Structure
<pre lang="markdown"> 
â”œâ”€â”€ checkpoints/ # Saved model weights (.pth) 
â”œâ”€â”€ dataset/ # Dataset root â”‚ 
    â”œâ”€â”€ train/ â”‚ 
    â”‚ â”œâ”€â”€ image/ # Training images â”‚ 
    â”‚ â””â”€â”€ mask/ # Ground-truth masks â”‚ 
    â”œâ”€â”€ val/ â”‚ 
    â”‚ â”œâ”€â”€ image/ # Validation images â”‚ 
    â”‚ â””â”€â”€ mask/ # Validation masks â”‚ 
    â””â”€â”€ test/ 
    â”‚ â”œâ”€â”€ image/ # Test images 
    â”‚ â””â”€â”€ mask/ # Test masks (optional) 
â”œâ”€â”€ outputs/ # Predicted masks generated by test.py 
â”œâ”€â”€ logs/ # TensorBoard & txt logs â”‚ 
â”œâ”€â”€ train.py # Train / fine-tune a model 
â”œâ”€â”€ test.py # Evaluate a checkpoint or export predictions â”‚ 
â”œâ”€â”€ model.py # Vanilla UNet / CompNet definitions â”œâ”€â”€ model_mnetv3_2_ca_sa.py # MobileNetV3 backboneâ”‚ 
â”œâ”€â”€ loss.py # BCE, Dice, Tversky, etc. 
â”œâ”€â”€ Hybrid_Eloss.py # Experimental hybrid edge loss â”‚ 
â”œâ”€â”€ utils.py # Metric calculators, I/O helpers, seeds 
â”œâ”€â”€ data.py # PyTorch Dataset & Dataloader wrappers â”‚ 
â”œâ”€â”€ requirements.txt # Exact package versions 
â””â”€â”€ README.md # Youâ€™re here  </pre>

## âš™ï¸ Installation

1. **Clone the repository**

```bash
git clone https://github.com/hlmhlr/Road-segmentation.git
cd road_segmentation
pip install -r requirements.txt
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```
âœ… Tip: Use a virtual environment:

```bash
conda create -n segrext python=3.8
conda activate segrext
```

## ğŸš€ Usage

â–¶ï¸ Training the Model

```bash
python train.py \
    --path ./dataset \
    --checkpoint_path ./checkpoints/best_model.pth \
    --train_log_path ./logs/train_log.txt \
    --batch_size 1 \
    --num_epochs 50
```
Arguments:

--path: Root path to the dataset.

--checkpoint_path: Where to save the trained .pth model.

--train_log_path: File to log loss and metrics.

--batch_size: Batch size for training.

--num_epochs: Number of training epochs.



## ğŸ§ª Testing / Inference
```bash
python test.py \
    --path ./dataset \
    --checkpoint_path ./checkpoints/best_model.pth \
    --results_path ./outputs
```
Arguments:

--path: Dataset path (should include test/image and test/mask).

--checkpoint_path: Path to the trained model file.

--results_path: Folder to save the predicted masks.


## ğŸ§¾ Dataset Format
The dataset must follow the structure as mentioned in the project structre above and all images are kept as .png files.

## ğŸ“ˆ Output & Metrics
At the end of testing, the following segmentation metrics are printed and saved:

Jaccard Index (IoU)

F1 Score

Recall

Precision

Accuracy

F2 Score

Inference FPS (Frames per Second)

Outputs:
Predicted masks are saved to the outputs/mask folder.

Evaluation results are stored in a .csv file inside the results directory.

## ğŸ“Œ Notes
Images are resized to 256Ã—256 before inference.

Predicted masks are binarized with a threshold of 0.5.

The model is evaluated on test.py using ground-truth masks.

The entire code supports CUDA if a GPU is available.


---
